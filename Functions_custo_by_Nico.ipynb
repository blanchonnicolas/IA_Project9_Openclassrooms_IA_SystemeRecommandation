{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eaf0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10a034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"Greens_d\")\n",
    "sns.light_palette(\"seagreen\", as_cmap=True)\n",
    "sns.color_palette(\"Greens_d\")\n",
    "\n",
    "#import plotly.express as px\n",
    "import tarfile\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "#import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom helper libraries\n",
    "import os\n",
    "#from os import listdir, path\n",
    "#from os.path import isfile, join, splitext\n",
    "\n",
    "import sys\n",
    "#import data.helpers as data_helpers\n",
    "#import visualization.helpers as viz_helpers\n",
    "\n",
    "# from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6464d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def Test_Imported_Functions():\n",
    "    print(\"Functions have been properly imported !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364802fc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0ccd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nrows_data(DATA_URL, nrows, DATASET_COLUMNS):\n",
    "    data_loaded = pd.read_csv(DATA_URL, nrows=nrows, names=DATASET_COLUMNS)\n",
    "    return (data_loaded)\n",
    "\n",
    "def load_all_data(DATA_URL, DATASET_COLUMNS):\n",
    "    data_loaded = pd.read_csv(DATA_URL, names=DATASET_COLUMNS)\n",
    "    return (data_loaded)\n",
    "\n",
    "def load_formatted_data(DATA_URL, DATASET_ENCODING, DATASET_COLUMNS):\n",
    "    data_loaded = pd.read_csv(DATA_URL, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "    return (data_loaded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90813b08",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16582c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data): \n",
    "    #Remove rows where important information are missing:\n",
    "    data_cleaned = data.dropna(axis = 0, how='all')\n",
    "    #Clean duplicates\n",
    "    data_cleaned = data_cleaned.drop_duplicates()\n",
    "    #Change content in lowercase\n",
    "    data_cleaned = data_cleaned.apply(lambda x: x.str.lower() if(x.dtype == 'object') else x)\n",
    "    #Filter order_dataset\n",
    "    return (data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae524af5",
   "metadata": {},
   "source": [
    "## Plot Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f188f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615659bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors_from_values_integer(values, palette_name):\n",
    "    # normalize the values to range [0, 1]\n",
    "    normalized = (values - min(values)) / (max(values) - min(values))\n",
    "    # convert to indices\n",
    "    indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)\n",
    "\n",
    "# def colors_from_values(values, palette_name):\n",
    "#     pal = sns.color_palette(palette_name, len(values))\n",
    "#     rank = values.argsort().argsort()   # http://stackoverflow.com/a/6266510/1628638\n",
    "#     palette=np.array(pal[::-1])[rank]\n",
    "#     return (palette)\n",
    "\n",
    "def colors_from_values_float(values: pd.Series, palette_name:str, ascending=True):\n",
    "    # convert to indices\n",
    "    values = values.sort_values(ascending=True).reset_index()\n",
    "    indices = values.sort_values(by=values.columns[0]).index\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5b52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Fill ratio in specified columns\n",
    "def plot_fill_ratio(data: pd.DataFrame, colunms_selected: list):\n",
    "    data_fill_ratio = pd.DataFrame(columns=['column_name', 'null_count', 'notnull_count'])\n",
    "    data_fill_ratio.drop(data_fill_ratio.index, inplace=True)        \n",
    "    for col in colunms_selected: \n",
    "        null_count = data[col].isna().sum()\n",
    "        notnull_count = data[col].notna().sum()\n",
    "        new_row = pd.DataFrame({'column_name':[col], 'null_count':[null_count], 'notnull_count':[notnull_count]})\n",
    "        data_fill_ratio = pd.concat([data_fill_ratio, new_row], ignore_index = None, axis = 0)\n",
    "    data_fill_ratio_study = pd.melt(data_fill_ratio.reset_index(), id_vars=['column_name'], value_vars=['null_count', 'notnull_count'])\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    #ax = sns.barplot(data=data_fill_ratio_study, x='value', y='column_name', hue='variable')\n",
    "    \n",
    "    ax = sns.barplot(data=data_fill_ratio_study, x='value', y='column_name', hue='variable', palette=\"Greens_d\")\n",
    "    ax.set_title('Null and NotNull Count per columns in dataframe')\n",
    "    plt.show()\n",
    "    data_fill_ratio_study.drop(data_fill_ratio_study.index, inplace=True)\n",
    "    return(data_fill_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d869e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot occurence by value present in specified column\n",
    "def plot_occurence_line(data: pd.DataFrame, colunm_name):\n",
    "    fig = px.line(data[colunm_name].value_counts())\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Number of occurence by {colunm_name} .\\nTOTAL = {len(data[colunm_name])}\",\n",
    "        width=900,\n",
    "        height=600,\n",
    "        #markers=True,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2cbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot distribution of dates\n",
    "def plot_peryearmonth(data: pd.DataFrame, date_column, plot_hue: bool, hue_column):\n",
    "    data['date_yearmonth'] = pd.to_datetime(data[date_column]).dt.to_period('M')\n",
    "    plt.figure(figsize=(15,10))\n",
    "    if (plot_hue == True):\n",
    "        ax1 = sns.countplot(x=\"date_yearmonth\", data=data.sort_values('date_yearmonth'), hue=hue_column, palette=\"Greens_d\")\n",
    "    else:\n",
    "        ax1 = sns.countplot(x=\"date_yearmonth\", data=data.sort_values('date_yearmonth'), palette=\"Greens_d\")\n",
    "    ax1.set_title(f'Distribution of {date_column} per month')\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Function to plot distribution of dates\n",
    "def plot_peryear(data: pd.DataFrame, date_column, plot_hue: bool, hue_column):\n",
    "    data['date_year'] = pd.to_datetime(data[date_column]).dt.to_period('Y')\n",
    "    plt.figure(figsize=(15,10))\n",
    "    if (plot_hue == True):\n",
    "        ax1 = sns.countplot(x=\"date_year\", data=data.sort_values('date_year'), hue=hue_column, palette=\"Greens_d\")\n",
    "    else:\n",
    "        ax1 = sns.countplot(x=\"date_year\", data=data.sort_values('date_year'), palette=\"Greens_d\")\n",
    "    ax1.set_title(f'Distribution of {date_column} per year')\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9921ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_columns(data: pd.DataFrame, colunms_selected: list, plot_hue: bool, hue_column):\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    if (plot_hue == True):\n",
    "        ax = sns.pairplot(data[colunms_selected], \n",
    "                             hue=hue_column, \n",
    "                             hue_order=sorted(data[hue_column].unique(),\n",
    "                             reverse=True)\n",
    "                            )\n",
    "    else:\n",
    "        ax = ax=sns.pairplot(data[colunms_selected]\n",
    "                            )\n",
    "    ax.fig.suptitle(f'Pairplot on selected columns')\n",
    "    plt.title(f'Pairplot on selected columns {colunms_selected}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f964220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot PIE Chart of n tops values in dataframe\n",
    "def plot_ntops_pie(data: pd.DataFrame, colunm_name, ntops: int, plot_others: bool, plot_na: bool):\n",
    "    podium_tops = pd.DataFrame(data[colunm_name].value_counts(dropna=True, sort=True).head(ntops))\n",
    "    if (plot_others == True):\n",
    "        remainings_counts = sum(data[colunm_name].value_counts(dropna=True)[ntops:])\n",
    "        remainings_below = pd.DataFrame({colunm_name : [remainings_counts]}, index=['others'])\n",
    "        podium_tops = pd.concat([podium_tops, remainings_below], ignore_index = None, axis = 0)\n",
    "    if (plot_na == True):\n",
    "        na_counts = data[colunm_name].isna().sum()\n",
    "        remainings_na = pd.DataFrame({colunm_name : [na_counts]}, index=['NAN'])\n",
    "        podium_tops = pd.concat([podium_tops, remainings_na], ignore_index = None, axis = 0)\n",
    "    \n",
    "    \n",
    "    #Définir la taille du graphique\n",
    "    plt.figure(figsize=(8,8))\n",
    "    #Définir lae type du graphique, ici PIE CHart avec en Labels l'index du nom des libelle\n",
    "    #l'autopct sert ici à afficher le % calculé avec 1 décimal derriere la virgule\n",
    "    plt.pie(podium_tops[colunm_name], labels=podium_tops.index, autopct='%1.1f%%')\n",
    "    #Afficher la légende en dessous du graphique au centre\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(0.1, -0.01), fancybox=True, shadow=None, ncol=2)\n",
    "    plt.title(f\"{ntops} most presents values identified in column {colunm_name} .\\nTOTAL unique = {len(data[colunm_name].unique())}\")\n",
    "    #Afficher le graphique\n",
    "    plt.show()\n",
    "    return(podium_tops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e01567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ntops_bar(data: pd.DataFrame, colunm_name, ntops: int, plot_others: bool, plot_na: bool):\n",
    "    podium_tops = pd.DataFrame(data[colunm_name].value_counts(dropna=True, sort=True).head(ntops))\n",
    "    if (plot_others == True):\n",
    "        remainings_counts = sum(data[colunm_name].value_counts(dropna=True)[ntops:])\n",
    "        remainings_below = pd.DataFrame({colunm_name : [remainings_counts]}, index=['others'])\n",
    "        podium_tops = pd.concat([podium_tops, remainings_below], ignore_index = None, axis = 0)\n",
    "    if (plot_na == True):\n",
    "        na_counts = data[colunm_name].isna().sum()\n",
    "        remainings_na = pd.DataFrame({colunm_name : [na_counts]}, index=['NAN'])\n",
    "        podium_tops = pd.concat([podium_tops, remainings_na], ignore_index = None, axis = 0)\n",
    "    #podium_tops = podium_tops.reset_index(drop=True)\n",
    "    #Définir la taille du graphique\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    #Définir lae type du graphique, ici BARPLOT avec en Labels l'index du nom des libelle\n",
    "    ax = sns.barplot(data=podium_tops, x=podium_tops.index, y=colunm_name, palette=colors_from_values_integer(podium_tops[colunm_name], \"Greens_d\"))\n",
    "    plt.title(f\"{ntops} most presents values identified in column {colunm_name} .\\nTOTAL unique = {len(data[colunm_name].unique())}\")\n",
    "    #Afficher le graphique\n",
    "    plt.show()\n",
    "    return(podium_tops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0ab79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that study boxplot\n",
    "def plot_boxplot(data: pd.DataFrame, x_axis, colunms_selected: list, plot_outliers: bool): \n",
    "    for col in colunms_selected:\n",
    "        sns.set()\n",
    "        fig, ax = plt.subplots(figsize=(15, 5))\n",
    "        sns.boxplot(x=x_axis, \n",
    "                    y=col, # column is chosen here\n",
    "                    data=data,\n",
    "                    #order=[\"a\", \"b\"],\n",
    "                    showfliers = plot_outliers,\n",
    "                    showmeans=True,\n",
    "                    )  \n",
    "        sns.despine(offset=10, trim=True) \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9261b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that study histogramme\n",
    "def plot_histogramme(histo_data: pd.DataFrame, column_value, colunms_group): \n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    #Plot the distribution\n",
    "    ax = sns.displot(data=histo_data, x=column_value, hue=colunms_group)\n",
    "    ax.move_legend(ax1, \"upper right\", bbox_to_anchor=(.55, .45), title=f'histogramme of {column_value}')\n",
    "    plt.title(f\"Distribution of {column_value} values\")\n",
    "    #plt.legend(loc='upper right')\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(f\"{column_value} ranges\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415f5d2",
   "metadata": {},
   "source": [
    "## Réduction de dimension\n",
    "### ACP (A Vérifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43b7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA functions:\n",
    "#Functions below are used for ACP\n",
    "def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n",
    "    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premières composantes\n",
    "        if d2 < n_comp:\n",
    "\n",
    "            # initialisation de la figure\n",
    "            fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            if lims is not None :\n",
    "                xmin, xmax, ymin, ymax = lims\n",
    "            elif pcs.shape[1] < 30 :\n",
    "                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n",
    "            else :\n",
    "                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n",
    "\n",
    "            # affichage des flèches\n",
    "            # s'il y a plus de 30 flèches, on n'affiche pas le triangle à leur extrémité\n",
    "            if pcs.shape[1] < 30 :\n",
    "                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n",
    "                   pcs[d1,:], pcs[d2,:], \n",
    "                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n",
    "                # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)\n",
    "            else:\n",
    "                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n",
    "                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n",
    "            \n",
    "            # affichage des noms des variables  \n",
    "            if labels is not None:  \n",
    "                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n",
    "                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n",
    "                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n",
    "            \n",
    "            # affichage du cercle\n",
    "            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='r')\n",
    "            plt.gca().add_artist(circle)\n",
    "\n",
    "            # définition des limites du graphique\n",
    "            plt.xlim(xmin, xmax)\n",
    "            plt.ylim(ymin, ymax)\n",
    "        \n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Cercle des corrélations (F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions below are used for ACP\n",
    "def display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, illustrative_var=None):\n",
    "    for d1,d2 in axis_ranks:\n",
    "        if d2 < n_comp:\n",
    " \n",
    "            # initialisation de la figure       \n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "        \n",
    "            # affichage des points\n",
    "            if illustrative_var is None:\n",
    "                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)\n",
    "                #plt.scatter(centres_reduced[:, d1], centres_reduced[:, d2], alpha=alpha, marker='x', s=100, linewidths=2,color='k', zorder=10)\n",
    "            else:\n",
    "                illustrative_var = np.array(illustrative_var)\n",
    "                for value in np.unique(illustrative_var):\n",
    "                    selected = np.where(illustrative_var == value)\n",
    "                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)\n",
    "                    #plt.scatter(centres_reduced[:, d1], centres_reduced[:, d2], alpha=alpha, marker='x', s=100, linewidths=2,color='k', zorder=10)\n",
    "                plt.legend()\n",
    "\n",
    "            # affichage des labels des points\n",
    "            if labels is not None:\n",
    "                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n",
    "                    plt.text(x, y, labels[i],\n",
    "                              fontsize='14', ha='center',va='center') \n",
    "                \n",
    "            # détermination des limites du graphique\n",
    "            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) / 1\n",
    "            plt.xlim([-boundary,boundary])\n",
    "            plt.ylim([-boundary,boundary])\n",
    "        \n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Projection des individus (sur F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9a6a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions below are used for ACP            \n",
    "def display_scree_plot(pca):\n",
    "    scree = pca.explained_variance_ratio_*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "    plt.ylabel(\"pourcentage d'inertie\")\n",
    "    plt.title(\"Eboulis des valeurs propres\")\n",
    "    plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a8287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_parallel_coordinates(df, num_clusters):\n",
    "    '''Display a parallel coordinates plot for the clusters in df'''\n",
    "\n",
    "    # Select data points for individual clusters\n",
    "    cluster_points = []\n",
    "    for i in range(num_clusters):\n",
    "        cluster_points.append(df[df.cluster==i])\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(12, 15))\n",
    "    title = fig.suptitle(\"Parallel Coordinates Plot for the Clusters\", fontsize=18)\n",
    "    fig.subplots_adjust(top=0.95, wspace=0)\n",
    "\n",
    "    # Display one plot for each cluster, with the lines for the main cluster appearing over the lines for the other clusters\n",
    "    for i in range(num_clusters):    \n",
    "        plt.subplot(num_clusters, 1, i+1)\n",
    "        for j,c in enumerate(cluster_points): \n",
    "            if i!= j:\n",
    "                pc = parallel_coordinates(c, 'cluster', color=[addAlpha(palette[j],0.2)])\n",
    "        pc = parallel_coordinates(cluster_points[i], 'cluster', color=[addAlpha(palette[i],0.5)])\n",
    "\n",
    "        # Stagger the axes\n",
    "        ax=plt.gca()\n",
    "        for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "            tick.set_pad(20)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6b9fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_parallel_coordinates_centroids(df, num_clusters):\n",
    "    '''Display a parallel coordinates plot for the centroids in df'''\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    title = fig.suptitle(\"Parallel Coordinates plot for the Centroids\", fontsize=18)\n",
    "    fig.subplots_adjust(top=0.9, wspace=0)\n",
    "\n",
    "    # Draw the chart\n",
    "    parallel_coordinates(df, 'cluster', color=palette)\n",
    "\n",
    "    # Stagger the axes\n",
    "    ax=plt.gca()\n",
    "    for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "        tick.set_pad(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d6a1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions below are used for Data Clustering    \n",
    "def plot_dendrogram(linked, names):\n",
    "    plt.figure(figsize=(10,15))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('distance')\n",
    "    dendrogram(\n",
    "        linked,\n",
    "        labels = names,\n",
    "        orientation = \"left\",\n",
    "        show_leaf_counts=True\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dd222",
   "metadata": {},
   "source": [
    "### Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb76607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour le graphe de Matrice de Confusion\n",
    "def matrix_pred_model(model, model_name, y_test, y_pred, figsize=(5,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"Matrice de confusion de {model_name}\")\n",
    "    sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,cmap = 'Greens',fmt=\"d\",cbar=False)\n",
    "    plt.xlabel(\"Classe prédite\")\n",
    "    plt.ylabel(\"Classe initiale\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de8b9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(model_name, fpr, tpr, figsize=(5,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"ROC Curve for {model_name}\")\n",
    "    plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, marker='.', label=model_name)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f670bc",
   "metadata": {},
   "source": [
    "### Determiner le seuil de décision (Classification binaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold_scores(data: pd.DataFrame, optimized_seuil):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(data['seuil'], data['FBeta-Score'], color='coral', lw=2, label='FBeta-Score')\n",
    "    plt.plot(data['seuil'], data['Precision_score'], color='cyan', lw=2, label='Precision_score')\n",
    "    plt.plot(data['seuil'], data['Accuracy_score'], color='blue', lw=2, label='Accuracy_score')\n",
    "    plt.plot(data['seuil'], data['Recall_score'], color='green', lw=2, label='Recall_score')\n",
    "    plt.plot(data['seuil'], data['F1_score'], color='red', lw=2, label='F1_score')\n",
    "    #plt.plot(store_score_thresholds['seuil'], store_score_thresholds['Roc_AUC_score'], color='red', lw=2, label='Roc_AUC_score')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Seuil', fontsize=14)\n",
    "    plt.ylabel('Scores', fontsize=14)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(f'Score optimized for binary classification obtained with threshold = {optimized_seuil}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a26ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, seuil=0.5):\n",
    "    if score <= seuil:\n",
    "        label = 0\n",
    "    elif score > seuil:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785f7294",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3091174520.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    F1_score = f1_score(y_test, y_pred) #, pos_label=4\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Fonction pour retourner les score des modèles\n",
    "\n",
    "###############################        ATTENTION : INITIALISATION A PREVOIR AVANT UTILISATION     ################\n",
    "#Initialisation de la table des résultats\n",
    "#score_column_names = [\"Model Type\",\"Model Name\",\"seuil\",\"F1-Score\", \"Recall_score\", \"Precision_score\", \"Accuracy_score\"]\n",
    "#store_score= pd.DataFrame(columns = score_column_names)\n",
    "\n",
    "# def evaluation(model,model_name,score_column_names,X_test,y_test, seuil = 0.5, binary_transform=False):\n",
    "#     # On récupère la prédiction de la valeur positive\n",
    "#     if binary_transform == True:\n",
    "#         y_prob = model.predict(X_test)\n",
    "#         y_pred = y_prob\n",
    "#     else:\n",
    "#         y_prob = model.predict_proba(X_test)[:,1]\n",
    "#         y_pred = np.where(y_prob > seuil, 1, 0)\n",
    "    \n",
    "#     # On créé un vecteur de prédiction à partir du vecteur de probabilités\n",
    "#     false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob) # y_prob instead of y_prob #, pos_label=4\n",
    "#     Roc_AUC_score = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "#     F1_score = f1_score(y_test, y_pred)\n",
    "#     FBeta_score = fbeta_score(y_test, y_pred, average='binary', beta=0.5, pos_label=1) #make_scorer(fbeta_score, beta = 2, pos_label=0 ,average = 'binary')\n",
    "#     Recall_score = recall_score(y_test, y_pred)\n",
    "#     Precision_score = precision_score(y_test, y_pred)\n",
    "#     Accuracy_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     #Plot functions\n",
    "#     matrix_pred_model(model, model_name, y_test, y_pred) \n",
    "#     plot_roc_auc_curve(model_name, false_positive_rate, true_positive_rate)\n",
    "    \n",
    "#     score_results = pd.Series([model, model_name, seuil, F1_score, FBeta_score, Recall_score, Precision_score, Accuracy_score, Roc_AUC_score])\n",
    "#     score_results_stored = pd.DataFrame([score_results.values],  columns = score_column_names)\n",
    "#     return(score_results_stored)\n",
    "\n",
    "# def evaluation_to_correct(model,model_name,score_column_names,store_score,X_test,y_test, seuil = 0.5):\n",
    "#     #Si le seuil n'est pas important\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     F1_score = f1_score(y_test, y_pred)#, pos_label=4\n",
    "#     Recall_score = recall_score(y_test, y_pred) #, pos_label=4\n",
    "#     Precision_score = precision_score(y_test, y_pred) #, pos_label=4\n",
    "#     Accuracy_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     matrix_pred_model(model, model_name, y_test,y_pred)  \n",
    "    \n",
    "#     #global store_score\n",
    "#     score_results = pd.Series([model, model_name, seuil, F1_score, Recall_score, Precision_score, Accuracy_score])\n",
    "#     score_results_stored = pd.DataFrame([score_results.values],  columns = score_column_names)\n",
    "#     store_score = pd.concat([store_score, score_results_stored], axis=0)\n",
    "#     return(store_score)\n",
    "\n",
    "def evaluation(model,model_name,score_column_names,X_test,y_test, seuil = 0.5, binary_predict=False, predict_proba_OK=False):\n",
    "    # On récupère la prédiction de la valeur positive\n",
    "    if binary_predict == True:\n",
    "        y_prob = model.predict(X_test)\n",
    "        y_pred = y_prob\n",
    "    elif ((binary_predict == False) and (predict_proba_OK == True)):\n",
    "        y_prob = model.predict_proba(X_test)[:,1]\n",
    "        y_pred = np.where(y_prob > seuil, 1, 0)\n",
    "    elif predict_proba_OK == False:\n",
    "        y_prob = model.predict(X_test)\n",
    "        y_pred = np.where(y_prob > seuil, 1, 0)\n",
    "        y_pred = y_pred.astype(int)\n",
    "    \n",
    "    # On créé un vecteur de prédiction à partir du vecteur de probabilités\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob) # y_prob instead of y_prob #, pos_label=4\n",
    "    Roc_AUC_score = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    F1_score = f1_score(y_test, y_pred)\n",
    "    FBeta_score = fbeta_score(y_test, y_pred, average='binary', beta=0.5, pos_label=1) #make_scorer(fbeta_score, beta = 2, pos_label=0 ,average = 'binary')\n",
    "    Recall_score = recall_score(y_test, y_pred)\n",
    "    Precision_score = precision_score(y_test, y_pred)\n",
    "    Accuracy_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #Plot functions\n",
    "    matrix_pred_model(model, model_name, y_test, y_pred) \n",
    "    plot_roc_auc_curve(model_name, false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    score_results = pd.Series([model, model_name, seuil, F1_score, FBeta_score, Recall_score, Precision_score, Accuracy_score, Roc_AUC_score])\n",
    "    score_results_stored = pd.DataFrame([score_results.values],  columns = score_column_names)\n",
    "    return(score_results_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ead5bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_result(data: pd.DataFrame, score, model_name):\n",
    "    #Définir la taille du graphique\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    #Définir lae type du graphique, ici BARPLOT avec en Labels l'index du nom des libelle\n",
    "    ax = sns.barplot(data=data, y=model_name, x=score, palette=colors_from_values_float(data[score], \"Greens_d\"))\n",
    "    ax.set_xlim((data[score].min() - 0.05), (data[score].max() + 0.02))\n",
    "    #ax = sns.barplot(data=data, x=model_name, y=score)\n",
    "    plt.title(f\"Score {score} max value is {round(data[score].max(), 2)} computed in model {data.loc[data[score] == data[score].max(), model_name]}\")\n",
    "    #Afficher le graphique\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7967f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, model_name):\n",
    "    acc=history.history['accuracy']\n",
    "    val_acc=history.history['val_accuracy']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    x=range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'g', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'c', label='Validation accuracy')\n",
    "    plt.title(f'Training and Validation Metric: Accuracy')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'g', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'c', label='Validation loss')\n",
    "    plt.title(f\"Training and Validation loss\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.suptitle(f\"Metric & Loss evolution during {model_name} training, (stopped by callback at epochs : {len(acc)})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774bc51",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('IA_Project8_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37e82b8de0ca04c20a1bf396b25e4fddd9a4c7101b46cea8b1ecc1a92174473c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
